{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1: Analysis of racial disparities in felony sentencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load packages and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic functionality\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "## can add others if you need them\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1: Load the data (0 points)\n",
    "\n",
    "Load the `sentencing_asof0405.csv` data\n",
    "\n",
    "*Notes*: You may receive a warning about mixed data types upon import; feel free to ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/06/5t48x2mx0lsc_1v4jxgdssjc0000gn/T/ipykernel_84493/1730725434.py:5: DtypeWarning: Columns (10,11,14,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = sentencing_data = pd.read_csv(\"/Users/ellascarola/desktop/QSS20/pset1_inputdata/sentencing_asof0405.csv\")\n"
     ]
    }
   ],
   "source": [
    "## load data on sentencing\n",
    "#df = sentencing_data = pd.read_csv(\"sentencing_asof0405.csv\")\n",
    "\n",
    "#Comment out if not Ella, this is just how its stored in my computer\n",
    "df = sentencing_data = pd.read_csv(\"/Users/ellascarola/desktop/QSS20/pset1_inputdata/sentencing_asof0405.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2: Print head, dimensions, info (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE_ID</th>\n",
       "      <th>CASE_PARTICIPANT_ID</th>\n",
       "      <th>RECEIVED_DATE</th>\n",
       "      <th>OFFENSE_CATEGORY</th>\n",
       "      <th>PRIMARY_CHARGE_FLAG</th>\n",
       "      <th>CHARGE_ID</th>\n",
       "      <th>CHARGE_VERSION_ID</th>\n",
       "      <th>DISPOSITION_CHARGED_OFFENSE_TITLE</th>\n",
       "      <th>CHARGE_COUNT</th>\n",
       "      <th>DISPOSITION_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>INCIDENT_CITY</th>\n",
       "      <th>INCIDENT_BEGIN_DATE</th>\n",
       "      <th>INCIDENT_END_DATE</th>\n",
       "      <th>LAW_ENFORCEMENT_AGENCY</th>\n",
       "      <th>LAW_ENFORCEMENT_UNIT</th>\n",
       "      <th>ARREST_DATE</th>\n",
       "      <th>FELONY_REVIEW_DATE</th>\n",
       "      <th>FELONY_REVIEW_RESULT</th>\n",
       "      <th>ARRAIGNMENT_DATE</th>\n",
       "      <th>UPDATED_OFFENSE_CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149765331439</td>\n",
       "      <td>175691153649</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>PROMIS Conversion</td>\n",
       "      <td>False</td>\n",
       "      <td>50510112469</td>\n",
       "      <td>116304211997</td>\n",
       "      <td>FIRST DEGREE MURDER</td>\n",
       "      <td>2</td>\n",
       "      <td>12/17/2014 12:00:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/9/1984 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO POLICE DEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>08/15/1984 12:00:00 AM</td>\n",
       "      <td>Charge(S) Approved</td>\n",
       "      <td>9/21/1984 12:00:00 AM</td>\n",
       "      <td>Homicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149765331439</td>\n",
       "      <td>175691153649</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>PROMIS Conversion</td>\n",
       "      <td>False</td>\n",
       "      <td>50510213021</td>\n",
       "      <td>98265074680</td>\n",
       "      <td>HOME INVASION</td>\n",
       "      <td>14</td>\n",
       "      <td>12/17/2014 12:00:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/9/1984 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO POLICE DEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>08/15/1984 12:00:00 AM</td>\n",
       "      <td>Charge(S) Approved</td>\n",
       "      <td>9/21/1984 12:00:00 AM</td>\n",
       "      <td>Homicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149765331439</td>\n",
       "      <td>175691153649</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>PROMIS Conversion</td>\n",
       "      <td>False</td>\n",
       "      <td>50516447217</td>\n",
       "      <td>131972895911</td>\n",
       "      <td>FIRST DEGREE MURDER</td>\n",
       "      <td>4</td>\n",
       "      <td>12/17/2014 12:00:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/9/1984 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO POLICE DEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>08/15/1984 12:00:00 AM</td>\n",
       "      <td>Charge(S) Approved</td>\n",
       "      <td>9/21/1984 12:00:00 AM</td>\n",
       "      <td>Homicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149765331439</td>\n",
       "      <td>175691153649</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>PROMIS Conversion</td>\n",
       "      <td>False</td>\n",
       "      <td>50516497493</td>\n",
       "      <td>131966356472</td>\n",
       "      <td>FIRST DEGREE MURDER</td>\n",
       "      <td>5</td>\n",
       "      <td>12/17/2014 12:00:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/9/1984 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO POLICE DEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>08/15/1984 12:00:00 AM</td>\n",
       "      <td>Charge(S) Approved</td>\n",
       "      <td>9/21/1984 12:00:00 AM</td>\n",
       "      <td>Homicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149765331439</td>\n",
       "      <td>175691153649</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>PROMIS Conversion</td>\n",
       "      <td>False</td>\n",
       "      <td>50516648320</td>\n",
       "      <td>98059642859</td>\n",
       "      <td>HOME INVASION</td>\n",
       "      <td>13</td>\n",
       "      <td>12/17/2014 12:00:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/9/1984 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO POLICE DEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>08/15/1984 12:00:00 AM</td>\n",
       "      <td>Charge(S) Approved</td>\n",
       "      <td>9/21/1984 12:00:00 AM</td>\n",
       "      <td>Homicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CASE_ID  CASE_PARTICIPANT_ID          RECEIVED_DATE  \\\n",
       "0  149765331439         175691153649  8/15/1984 12:00:00 AM   \n",
       "1  149765331439         175691153649  8/15/1984 12:00:00 AM   \n",
       "2  149765331439         175691153649  8/15/1984 12:00:00 AM   \n",
       "3  149765331439         175691153649  8/15/1984 12:00:00 AM   \n",
       "4  149765331439         175691153649  8/15/1984 12:00:00 AM   \n",
       "\n",
       "    OFFENSE_CATEGORY  PRIMARY_CHARGE_FLAG    CHARGE_ID  CHARGE_VERSION_ID  \\\n",
       "0  PROMIS Conversion                False  50510112469       116304211997   \n",
       "1  PROMIS Conversion                False  50510213021        98265074680   \n",
       "2  PROMIS Conversion                False  50516447217       131972895911   \n",
       "3  PROMIS Conversion                False  50516497493       131966356472   \n",
       "4  PROMIS Conversion                False  50516648320        98059642859   \n",
       "\n",
       "  DISPOSITION_CHARGED_OFFENSE_TITLE  CHARGE_COUNT        DISPOSITION_DATE  \\\n",
       "0               FIRST DEGREE MURDER             2  12/17/2014 12:00:00 AM   \n",
       "1                     HOME INVASION            14  12/17/2014 12:00:00 AM   \n",
       "2               FIRST DEGREE MURDER             4  12/17/2014 12:00:00 AM   \n",
       "3               FIRST DEGREE MURDER             5  12/17/2014 12:00:00 AM   \n",
       "4                     HOME INVASION            13  12/17/2014 12:00:00 AM   \n",
       "\n",
       "   ... INCIDENT_CITY   INCIDENT_BEGIN_DATE INCIDENT_END_DATE  \\\n",
       "0  ...           NaN  8/9/1984 12:00:00 AM               NaN   \n",
       "1  ...           NaN  8/9/1984 12:00:00 AM               NaN   \n",
       "2  ...           NaN  8/9/1984 12:00:00 AM               NaN   \n",
       "3  ...           NaN  8/9/1984 12:00:00 AM               NaN   \n",
       "4  ...           NaN  8/9/1984 12:00:00 AM               NaN   \n",
       "\n",
       "  LAW_ENFORCEMENT_AGENCY LAW_ENFORCEMENT_UNIT            ARREST_DATE  \\\n",
       "0    CHICAGO POLICE DEPT                  NaN  8/15/1984 12:00:00 AM   \n",
       "1    CHICAGO POLICE DEPT                  NaN  8/15/1984 12:00:00 AM   \n",
       "2    CHICAGO POLICE DEPT                  NaN  8/15/1984 12:00:00 AM   \n",
       "3    CHICAGO POLICE DEPT                  NaN  8/15/1984 12:00:00 AM   \n",
       "4    CHICAGO POLICE DEPT                  NaN  8/15/1984 12:00:00 AM   \n",
       "\n",
       "       FELONY_REVIEW_DATE FELONY_REVIEW_RESULT       ARRAIGNMENT_DATE  \\\n",
       "0  08/15/1984 12:00:00 AM   Charge(S) Approved  9/21/1984 12:00:00 AM   \n",
       "1  08/15/1984 12:00:00 AM   Charge(S) Approved  9/21/1984 12:00:00 AM   \n",
       "2  08/15/1984 12:00:00 AM   Charge(S) Approved  9/21/1984 12:00:00 AM   \n",
       "3  08/15/1984 12:00:00 AM   Charge(S) Approved  9/21/1984 12:00:00 AM   \n",
       "4  08/15/1984 12:00:00 AM   Charge(S) Approved  9/21/1984 12:00:00 AM   \n",
       "\n",
       "  UPDATED_OFFENSE_CATEGORY  \n",
       "0                 Homicide  \n",
       "1                 Homicide  \n",
       "2                 Homicide  \n",
       "3                 Homicide  \n",
       "4                 Homicide  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(248146, 41)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 248146 entries, 0 to 248145\n",
      "Data columns (total 41 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   CASE_ID                            248146 non-null  int64  \n",
      " 1   CASE_PARTICIPANT_ID                248146 non-null  int64  \n",
      " 2   RECEIVED_DATE                      248146 non-null  object \n",
      " 3   OFFENSE_CATEGORY                   248146 non-null  object \n",
      " 4   PRIMARY_CHARGE_FLAG                248146 non-null  bool   \n",
      " 5   CHARGE_ID                          248146 non-null  int64  \n",
      " 6   CHARGE_VERSION_ID                  248146 non-null  int64  \n",
      " 7   DISPOSITION_CHARGED_OFFENSE_TITLE  248146 non-null  object \n",
      " 8   CHARGE_COUNT                       248146 non-null  int64  \n",
      " 9   DISPOSITION_DATE                   248146 non-null  object \n",
      " 10  DISPOSITION_CHARGED_CHAPTER        248146 non-null  object \n",
      " 11  DISPOSITION_CHARGED_ACT            242771 non-null  object \n",
      " 12  DISPOSITION_CHARGED_SECTION        242771 non-null  object \n",
      " 13  DISPOSITION_CHARGED_CLASS          248127 non-null  object \n",
      " 14  DISPOSITION_CHARGED_AOIC           248122 non-null  object \n",
      " 15  CHARGE_DISPOSITION                 248146 non-null  object \n",
      " 16  CHARGE_DISPOSITION_REASON          904 non-null     object \n",
      " 17  SENTENCE_JUDGE                     247404 non-null  object \n",
      " 18  SENTENCE_COURT_NAME                246761 non-null  object \n",
      " 19  SENTENCE_COURT_FACILITY            246216 non-null  object \n",
      " 20  SENTENCE_PHASE                     248146 non-null  object \n",
      " 21  SENTENCE_DATE                      248146 non-null  object \n",
      " 22  SENTENCE_TYPE                      248146 non-null  object \n",
      " 23  CURRENT_SENTENCE_FLAG              248146 non-null  bool   \n",
      " 24  COMMITMENT_TYPE                    246464 non-null  object \n",
      " 25  COMMITMENT_TERM                    246434 non-null  object \n",
      " 26  COMMITMENT_UNIT                    246434 non-null  object \n",
      " 27  LENGTH_OF_CASE_in_Days             229126 non-null  float64\n",
      " 28  AGE_AT_INCIDENT                    238359 non-null  float64\n",
      " 29  RACE                               246879 non-null  object \n",
      " 30  GENDER                             247337 non-null  object \n",
      " 31  INCIDENT_CITY                      228745 non-null  object \n",
      " 32  INCIDENT_BEGIN_DATE                239122 non-null  object \n",
      " 33  INCIDENT_END_DATE                  22008 non-null   object \n",
      " 34  LAW_ENFORCEMENT_AGENCY             239405 non-null  object \n",
      " 35  LAW_ENFORCEMENT_UNIT               76408 non-null   object \n",
      " 36  ARREST_DATE                        242981 non-null  object \n",
      " 37  FELONY_REVIEW_DATE                 171907 non-null  object \n",
      " 38  FELONY_REVIEW_RESULT               171907 non-null  object \n",
      " 39  ARRAIGNMENT_DATE                   229126 non-null  object \n",
      " 40  UPDATED_OFFENSE_CATEGORY           248146 non-null  object \n",
      "dtypes: bool(2), float64(2), int64(5), object(32)\n",
      "memory usage: 74.3+ MB\n"
     ]
    }
   ],
   "source": [
    "## print head\n",
    "df.head()\n",
    "## print dimensions\n",
    "df.shape\n",
    "## print info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part one: data cleaning/interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Understanding the unit of analysis (5 points)\n",
    "\n",
    "- Print the number of unique values for the following columns. Do so in a way that avoids copying/pasting code for \n",
    "the three:\n",
    "\n",
    "    - Cases (`CASE_ID`)\n",
    "    - People in that case (`CASE_PARTICIPANT_ID`)\n",
    "    - Charges (`CHARGE_ID`)\n",
    "\n",
    "- Write a couple sentences on the following and show an example of each (e.g., a case involving multiple people):\n",
    "    \n",
    "    - Why there are more unique people than unique cases?\n",
    "    - Why there are more unique charges than unique people?\n",
    "\n",
    "- Print the mean and median number of charges per case/participant \n",
    "\n",
    "- Print the mean and median number of participants per case\n",
    "\n",
    "- Does the data seem to enable us to follow the same defendant across different cases they're charged in? Write 1 sentence in support of your conclusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CASE_ID                197519\n",
       "CASE_PARTICIPANT_ID    211977\n",
       "CHARGE_ID              229015\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## printing number of unique values for 3 CASE_ID, CASE_PARTICIPANT_ID, CHARGE_ID columns:\n",
    "df[[\"CASE_ID\", \"CASE_PARTICIPANT_ID\", \"CHARGE_ID\"]].nunique() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE_ID</th>\n",
       "      <th>CASE_PARTICIPANT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>166402790922</td>\n",
       "      <td>144234439761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>166402790922</td>\n",
       "      <td>144234534133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CASE_ID  CASE_PARTICIPANT_ID\n",
       "92   166402790922         144234439761\n",
       "102  166402790922         144234534133"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## There are more unique people than unique cases because some of the cases involve\n",
    "## multiple people or co-defendants. \n",
    "\n",
    "## Example of a case involving multiple people:\n",
    "participants_per_case = df.groupby(\"CASE_ID\")[\"CASE_PARTICIPANT_ID\"].nunique()\n",
    "example_case_id = participants_per_case[participants_per_case > 1].index[0]\n",
    "\n",
    "df[df[\"CASE_ID\"] == example_case_id][[\"CASE_ID\", \"CASE_PARTICIPANT_ID\"]].drop_duplicates()\n",
    "## Here we are interested in looking at one case that has at least 2 unique participants. We drop duplicates so that it doesn't list \n",
    "## participants more than once. As we can see, Case #166402790922 involves 2 participants: 144234439761 and 144234534133.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE_ID</th>\n",
       "      <th>CASE_PARTICIPANT_ID</th>\n",
       "      <th>CHARGE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10561</th>\n",
       "      <td>290136075812</td>\n",
       "      <td>97581722610</td>\n",
       "      <td>138443602912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10562</th>\n",
       "      <td>290136075812</td>\n",
       "      <td>97581722610</td>\n",
       "      <td>138495990272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10563</th>\n",
       "      <td>290136075812</td>\n",
       "      <td>97581722610</td>\n",
       "      <td>138496040547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10564</th>\n",
       "      <td>290136075812</td>\n",
       "      <td>97581722610</td>\n",
       "      <td>138495939996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CASE_ID  CASE_PARTICIPANT_ID     CHARGE_ID\n",
       "10561  290136075812          97581722610  138443602912\n",
       "10562  290136075812          97581722610  138495990272\n",
       "10563  290136075812          97581722610  138496040547\n",
       "10564  290136075812          97581722610  138495939996"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## There are more unique charges than unique people because, in some cases, people are charged\n",
    "## with multiple offenses.\n",
    "\n",
    "## Example of one person being charged with multiple unique offenses in a case: \n",
    "charges_per_person = df.groupby(\"CASE_PARTICIPANT_ID\")[\"CHARGE_ID\"].nunique()\n",
    "example_person_id = charges_per_person[charges_per_person > 1].index[0]\n",
    "\n",
    "df[df[\"CASE_PARTICIPANT_ID\"] == example_person_id][[\"CASE_ID\", \"CASE_PARTICIPANT_ID\", \"CHARGE_ID\"]].drop_duplicates()\n",
    "## Here we are interested in looking at one participant that has at least 2 unique charges for one case. As we can see, for Case #290136075812,\n",
    "## participant 97581722610 has 4 unique charges: 138443602912, 138495990272, 138496040547, 138495939996."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean unique charges per case: 1.1594580774507768\n",
      "median unique charges per case: 1.0\n"
     ]
    }
   ],
   "source": [
    "## Print the mean and median number of charges per case. **For all of these calcuations, I am assuming\n",
    "## we are interested in the mean/median number of UNIQUE charges or participants.\n",
    "\n",
    "charges_per_case = df.groupby(\"CASE_ID\")[\"CHARGE_ID\"].nunique()\n",
    "print(\"mean unique charges per case: \" + str(charges_per_case.mean()))\n",
    "print(\"median unique charges per case: \" + str(charges_per_case.median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean unique charges per participant: 1.1261457610967227\n",
      "median unique charges per participant: 1.0\n"
     ]
    }
   ],
   "source": [
    "## Print the mean and median number of charges per participant. **For all of these calcuations, I am assuming\n",
    "## we are interested in the mean/median number of UNIQUE charges or participants.\n",
    "\n",
    "charges_per_participant = df.groupby(\"CASE_PARTICIPANT_ID\")[\"CHARGE_ID\"].nunique()\n",
    "print(\"mean unique charges per participant: \" + str(charges_per_participant.mean()))\n",
    "print(\"median unique charges per participant: \" + str(charges_per_participant.median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean unique participants per case: 1.0731980214561636\n",
      "median unique participants per case: 1.0\n"
     ]
    }
   ],
   "source": [
    "## Print the mean and median number of participants per case. **For all of these calcuations, I am assuming\n",
    "## we are interested in the mean/median number of UNIQUE charges or participants.\n",
    "\n",
    "participants_per_case = df.groupby(\"CASE_ID\")[\"CASE_PARTICIPANT_ID\"].nunique()\n",
    "print(\"mean unique participants per case: \" + str(participants_per_case.mean()))\n",
    "print(\"median unique participants per case: \" + str(participants_per_case.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: CASE_ID, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "## Given the following check, the data does not seem to enable us to follow the same \n",
    "## defendant across different cases, as each CASE_PARTICIPANT_ID appears in only one CASE_ID\n",
    "## and there are no other participant ID variables that we can use.\n",
    "\n",
    "participant_case_count = df.groupby(\"CASE_PARTICIPANT_ID\")[\"CASE_ID\"].nunique()\n",
    "participants_w_mult_cases = participant_case_count[participant_case_count > 1]\n",
    "print(participants_w_mult_cases.head())\n",
    "\n",
    "## Since no participants are printed in the output, no participant_ID is associated with\n",
    "## more than one case. Defendants do not appear in multiple cases, so we cannot track them across cases.\n",
    "\n",
    "## We use this to check if there are alternative participant ID columns that may track participants across cases. \n",
    "## From the output, we see that this isn't so.\n",
    "## print([col for col in df.columns if \"ID\" in col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1: Which offense is final? (3 points)\n",
    "\n",
    "- First, read the data documentation [link](https://datacatalog.cookcountyil.gov/api/views/tg8v-tm6u/files/8597cdda-f7e1-44d1-b0ce-0a4e43f8c980?download=true&filename=CCSAO%20Data%20Glossary.pdf) and summarize in your own words the differences between `OFFENSE_CATEGORY` and `UPDATED_OFFENSE_CATEGORY` \n",
    "\n",
    "- Construct an indicator `is_changed_offense` that's True for case-participant-charge observations (rows) where there's a difference between the original charge (offense category) and the most current charge (updated offense category). What are some of the more common changed offenses? (can just print result of sort_values based on original offense category)\n",
    "\n",
    "- Print one example of a changed offense from one of these categories and comment on what the reason may be\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarize the differences between OFFENSE_CATEGORY and UPDATED_OFFENSE_CATEGORY:\n",
    "\n",
    "## OFFENSE_CATEGORY corresponds to the offense assigned to an individual at the time \n",
    "## when initial charges are filed. As the case evolves, the offense assigned to an individual \n",
    "## can change, so UPDATED_OFFENSE_CATEGORY reflects the most recent offense charge brought\n",
    "## against an individual. \n",
    "\n",
    "## A preliminary example of this, found by running \n",
    "## df[[\"OFFENSE_CATEGORY\", \"UPDATED_OFFENSE_CATEGORY\"]] \n",
    "## is a case in which what was initally categorized as a \"home invasion\" became \n",
    "## a \"UUW - Unlawful Use of Weapon.\" A potential reason is because through investigation, it was\n",
    "## found that the weapon played a larger part in teh case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OFFENSE_CATEGORY\n",
       "PROMIS Conversion               6394\n",
       "DUI                             3896\n",
       "UUW - Unlawful Use of Weapon    2155\n",
       "Other Offense                   2125\n",
       "Aggravated Battery              1927\n",
       "                                ... \n",
       "Perjury                            4\n",
       "Prostitution                       3\n",
       "Compelling Gang Membership         2\n",
       "Benefit Recipient Fraud            2\n",
       "Violate Bail Bond                  2\n",
       "Name: count, Length: 88, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Construct \"is_changed_offense\" indicator\n",
    "is_changed_offense = df[\"OFFENSE_CATEGORY\"] != df[\"UPDATED_OFFENSE_CATEGORY\"]\n",
    "df[\"is_changed_offense\"] = is_changed_offense\n",
    "\n",
    "## check:\n",
    "## df[[\"OFFENSE_CATEGORY\", \"UPDATED_OFFENSE_CATEGORY\", \"is_changed_offense\"]]\n",
    "\n",
    "\n",
    "## What are the most common changes offenses?\n",
    "changed_offenses = df[df[\"is_changed_offense\"]== True]\n",
    "changed_offenses_count = changed_offenses[\"OFFENSE_CATEGORY\"].value_counts().sort_values(ascending=False)\n",
    "changed_offenses_count\n",
    "\n",
    "## The most common changed offenses are PROMIS Conversion, DUI, and Unlawful Use of Weapon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE_ID</th>\n",
       "      <th>CASE_PARTICIPANT_ID</th>\n",
       "      <th>OFFENSE_CATEGORY</th>\n",
       "      <th>UPDATED_OFFENSE_CATEGORY</th>\n",
       "      <th>is_changed_offense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>217767855783</td>\n",
       "      <td>209397040606</td>\n",
       "      <td>Aggravated DUI</td>\n",
       "      <td>Driving With Suspended Or Revoked License</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CASE_ID  CASE_PARTICIPANT_ID OFFENSE_CATEGORY  \\\n",
       "2048  217767855783         209397040606   Aggravated DUI   \n",
       "\n",
       "                       UPDATED_OFFENSE_CATEGORY  is_changed_offense  \n",
       "2048  Driving With Suspended Or Revoked License                True  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Print one example of a changed offense from one of these categories and comment on what the reason may be\n",
    "\n",
    "changed_example = df[(df[\"is_changed_offense\"]) & (df[\"OFFENSE_CATEGORY\"].str.contains(\"DUI\"))].head(1)\n",
    "changed_example[[\"CASE_ID\", \"CASE_PARTICIPANT_ID\", \"OFFENSE_CATEGORY\", \"UPDATED_OFFENSE_CATEGORY\", \"is_changed_offense\"]]\n",
    "\n",
    "## Maybe  this defendant's offense was changed from Aggravated DUI to Driving With a Suspended or Revoked\n",
    "## License because the prosecution didn't have enough evidence to prove that he/she was drinking\n",
    "## and driving or because the defense attornery worked out a deal to make the offense and resulting sentence\n",
    "## less severe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2: Simplifying the charges (5 points)\n",
    "\n",
    "Using the field (`UPDATED_OFFENSE_CATEGORY`), create a new field, `simplified_offense_derived`, that simplifies the many offense categories into broader buckets using the following process:\n",
    "\n",
    "First, combine all offenses beginning with \"Aggravated\" into a single category without that prefix (e.g., Aggravated Battery and Battery just becomes Battery)\n",
    "\n",
    "Then:\n",
    "- Combine all offenses with arson into a single arson category (`Arson`)\n",
    "- Combine all offenses with homicide into a single homicide category (`Homicide`)\n",
    "- Combine all offenses with vehicle/vehicular in the name into a single vehicle category (`Vehicle-related`)\n",
    "- Combine all offenses with battery in the name into a single battery category (`Battery`)\n",
    "\n",
    "Try to do so efficiently (e.g., using map and a dictionary or np.select rather than separate line for each recoded offense)\n",
    "\n",
    "Print the difference between the # of unique offenses in the original `UPDATED_OFFENSE_CATEGORY` field and the # of unique offenses in your new `simplified_offense_derived` field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First combine all \"Aggravated\" offenses into a single category w/o prefix\n",
    "\n",
    "df[\"simplified_offense_derived\"] = df[\"UPDATED_OFFENSE_CATEGORY\"]\n",
    "df[\"simplified_offense_derived\"] = df[\"UPDATED_OFFENSE_CATEGORY\"].apply(\n",
    "    lambda x: x.replace(\"Aggravated \", \"\") if x.startswith(\"Aggravated \") else x\n",
    ")\n",
    "\n",
    "## Check:\n",
    "## df[\"UPDATED_OFFENSE_CATEGORY\"].str.startswith(\"Aggravated \").sum()\n",
    "## df[\"simplified_offense_derived\"].str.startswith(\"Aggravated \").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now combine other types of offenses according to the descriptions above:\n",
    "\n",
    "conditions = [\n",
    "    df[\"UPDATED_OFFENSE_CATEGORY\"].str.contains(\"arson\", case=False, na=False),\n",
    "    df[\"UPDATED_OFFENSE_CATEGORY\"].str.contains(\"homicide\", case=False, na=False),\n",
    "    df[\"UPDATED_OFFENSE_CATEGORY\"].str.contains(\"vehicle|vehicular\", case=False, na=False),\n",
    "    df[\"UPDATED_OFFENSE_CATEGORY\"].str.contains(\"battery\", case=False, na=False),\n",
    "]\n",
    "\n",
    "categories = [\n",
    "    \"Arson\",\n",
    "    \"Homicide\",\n",
    "    \"Vehicle-related\",\n",
    "    \"Battery\"\n",
    "]\n",
    "\n",
    "df[\"simplified_offense_derived\"] = np.select(\n",
    "    conditions,\n",
    "    categories,\n",
    "    default = df[\"simplified_offense_derived\"])\n",
    "\n",
    "## Check:\n",
    "## df[[\"UPDATED_OFFENSE_CATEGORY\", \"simplified_offense_derived\"]][df[\"simplified_offense_derived\"].str.contains(\"homicide|arson|vehicle|vehicular|batter\",case=False, na=False)].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between original and simplified offenses: 14\n"
     ]
    }
   ],
   "source": [
    "## Print difference between # of unique offenses in original offense category and simplified offense category:\n",
    "\n",
    "original_unique = df[\"UPDATED_OFFENSE_CATEGORY\"].nunique()\n",
    "simplified_unique = df[\"simplified_offense_derived\"].nunique()\n",
    "\n",
    "\n",
    "print(\"Difference between original and simplified offenses:\", original_unique - simplified_unique)\n",
    "\n",
    "## Check:\n",
    "## original_unique\n",
    "## simplified_unique\n",
    "\n",
    "## df[\"UPDATED_OFFENSE_CATEGORY\"].unique()\n",
    "## df[\"simplified_offense_derived\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3: Cleaning additional variables (10 points)\n",
    "\n",
    "Clean the following variables; make sure to retain the original variable in data and use the derived suffix so it's easier to pull these cleaned out variables later (e.g., `age_derived`) to indicate this was a transformation\n",
    "\n",
    "- Race: create True/false indicators for `is_black_derived` (Black only or mixed race with hispanic), Non-Black Hispanic, so either hispanic alone or white hispanic (`is_hisp_derived`), White non-hispanic (`is_white_derived`), or none of the above (`is_othereth_derived`)\n",
    "\n",
    "- Gender: create a boolean true/false indicator for `is_male_derived` (false is female, unknown, or other)\n",
    "\n",
    "- Age at incident: you notice outliers like 130-year olds. Winsorsize the top 0.01% of values to be equal to the 99.99th percentile value pre-winsorization. Call this `age_derived`\n",
    "\n",
    "- Create `sentenceymd_derived` that's a version of `SENTENCING_DATE` converted to datetime format. Also create a rounded version, `sentenceym_derived`, that's rounded down to the first of the month and the year (e.g., 01-05-2016 and 01-27-2016 each become 01-01-2016)\n",
    "    - Hint: all timestamps are midnight so u can strip in conversion. For full credit, before converting, you notice that some of the years have been mistranscribed (e.g., 291X or 221X instead of 201X). Programatically fix those (eg 2914 -> 2014). Even after cleaning, there will still be some that are after the year 2021 that we'll filter out later. For partial credit, you can ignore the timestamps that cause errors and set errors = \"coerce\" within `pd.to_datetime()` to allow the conversion to proceed. \n",
    "\n",
    "- Sentencing judge: create an identifier (`judgeid_derived`) for each unique judge (`SENTENCE_JUDGE`) structured as judge_1, judge_2...., with the order determined by sorting the judges (will sort on fname then last). When finding unique judges, there are various duplicates we could weed out --- for now, just focus on (1) the different iterations of Doug/Douglas Simpson, (2) the different iterations of Shelley Sutker (who appears both with her maiden name and her hyphenated married name). \n",
    "     - Hint: due to mixed types, you may need to cast the `SENTENCE_JUDGE` var to a diff type to sort\n",
    "\n",
    "After finishing, print a random sample of 10 rows (data.sample(n = 10)) with the original and cleaned columns for the relevant variables to validate your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Race:\n",
    "## to se what the race categories are:\n",
    "## df[\"RACE\"].unique()\n",
    "\n",
    "df[\"is_black_derived\"] = df[\"RACE\"].str.contains(\"Black\", case=False, na=False)\n",
    "df[\"is_hisp_derived\"] = df[\"RACE\"].str.contains(\"Hispanic\", case=False, na=False) & ~df[\"is_black_derived\"]\n",
    "df[\"is_white_derived\"] = df[\"RACE\"].str.contains(\"White\", case=False, na=False) & ~df[\"is_hisp_derived\"]\n",
    "df[\"is_othereth_derived\"] = ~df[\"is_black_derived\"] & ~df[\"is_hisp_derived\"] & ~df[\"is_white_derived\"]\n",
    "\n",
    "## check - we hope to see all the race variables coded correctly:\n",
    "## df[[\"RACE\", \"is_black_derived\", \"is_hisp_derived\", \"is_white_derived\", \"is_othereth_derived\"]].sample(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gender:\n",
    "df[\"is_male_derived\"] = df[\"GENDER\"].str.strip().str.lower() == \"male\"\n",
    "\n",
    "## check - we hope to see is_male_derived coded correctly:\n",
    "## df[[\"GENDER\", \"is_male_derived\"]].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Age at Incident:\n",
    "df[\"age_derived\"] = df[\"AGE_AT_INCIDENT\"]\n",
    "age_cap = df[\"age_derived\"].quantile(0.9999)\n",
    "df.loc[df[\"age_derived\"] > age_cap, \"age_derived\"] = age_cap\n",
    "\n",
    "## check - we hope to see 0 rows:\n",
    "## print(df[df[\"age_derived\"] > age_cap].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/06/5t48x2mx0lsc_1v4jxgdssjc0000gn/T/ipykernel_84493/4294631153.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"sentenceymd_derived\"] = pd.to_datetime(df[\"sentencing_date_clean\"], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "## Sentencing Date: \n",
    "df[\"sentencing_date_clean\"] = df[\"SENTENCE_DATE\"].astype(str).str.strip()\n",
    "\n",
    "## This is repetitive, but it was faster for me to do it this way than with a loop.\n",
    "df[\"sentencing_date_clean\"] = df[\"sentencing_date_clean\"].str.replace(\"291\", \"201\")\n",
    "df[\"sentencing_date_clean\"] = df[\"sentencing_date_clean\"].str.replace(\"221\", \"201\")\n",
    "df[\"sentencing_date_clean\"] = df[\"sentencing_date_clean\"].str.replace(\"220\", \"200\")  \n",
    "df[\"sentencing_date_clean\"] = df[\"sentencing_date_clean\"].str.replace(\"211\", \"201\")\n",
    "df[\"sentencing_date_clean\"] = df[\"sentencing_date_clean\"].str.replace(\"210\", \"200\")\n",
    "\n",
    "df[\"sentenceymd_derived\"] = pd.to_datetime(df[\"sentencing_date_clean\"], errors=\"coerce\")\n",
    "df[\"sentenceym_derived\"] = df[\"sentenceymd_derived\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "## since we no longer need this cleaned date column anymore:\n",
    "df = df.drop(columns=[\"sentencing_date_clean\"])\n",
    "\n",
    "## Checks - we hope to not see any wonky years:\n",
    "## df[\"sentenceymd_derived\"].dt.year.unique()\n",
    "## df[\"sentenceym_derived\"].dt.year.unique()\n",
    "## df[[\"SENTENCE_DATE\", \"sentenceymd_derived\", \"sentenceym_derived\"]].sample(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentencing Judge:\n",
    "df[\"judges_cleaned\"] = df[\"SENTENCE_JUDGE\"].astype(str)\n",
    "\n",
    "## Dealing with Doug and Shelley:\n",
    "is_doug = df[\"SENTENCE_JUDGE\"].str.contains(\"Douglas\", case=False, na=False) & df[\"SENTENCE_JUDGE\"].str.contains(\"Simpson\", case=False, na=False)\n",
    "\n",
    "is_shelley = df[\"SENTENCE_JUDGE\"].str.contains(\"Sutker-\", case=False, na=False)\n",
    "\n",
    "df.loc[is_doug, \"judges_cleaned\"] = \"Doug Simpson\"\n",
    "df.loc[is_shelley, \"judges_cleaned\"] = \"Shelley Sutker\"\n",
    "\n",
    "\n",
    "## Check we cleaned Doug and Shelley's names the right way:\n",
    "## df[df[\"SENTENCE_JUDGE\"].str.contains(\"Simpson\", case=False, na=False)][[\"SENTENCE_JUDGE\", \"judges_cleaned\"]].drop_duplicates()\n",
    "## df[df[\"SENTENCE_JUDGE\"].str.contains(\"Sutker\", case=False, na=False)][[\"SENTENCE_JUDGE\", \"judges_cleaned\"]].drop_duplicates()\n",
    "\n",
    "## To do the rest of judgeid:\n",
    "##list of unique judge names\n",
    "judge_names = list(df[\"judges_cleaned\"].unique())\n",
    "\n",
    "## Looked up how to use name split online, since I was having trouble figuring out how \n",
    "## to split by spaces given lots of judges have middle names included.\n",
    "judge_names.sort(key=lambda name: (name.split()[0].lower(), name.split()[-1].lower()))\n",
    "\n",
    "## we add 1 to i so that we start counting judges at 1, not 0; the length of judge_names tells\n",
    "## us how many unique judges there are, so we can code by this\n",
    "judge_ids = [\"judge_\" + str(i + 1) for i in range(len(judge_names))]\n",
    "\n",
    "judge_id_dict = dict(zip(judge_names, judge_ids))\n",
    "\n",
    "df[\"judgeid_derived\"] = df[\"judges_cleaned\"].map(judge_id_dict)\n",
    "\n",
    "## since we no longer need the cleaned judge column anymore:\n",
    "df = df.drop(columns=[\"judges_cleaned\"])\n",
    "\n",
    "## Check - we hope to see unique judges have only one judgeid_derived value and that \n",
    "## first names early on in the alphabet correspond to low ID numbers. We also want the output\n",
    "## to show that every judge in judges_cleaned column has exactly one unique judgeid_derived. \n",
    "## df[[\"SENTENCE_JUDGE\", \"judgeid_derived\"]].sample(20)\n",
    "## df.groupby(\"judges_cleaned\")[\"judgeid_derived\"].nunique().value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE</th>\n",
       "      <th>is_black_derived</th>\n",
       "      <th>is_hisp_derived</th>\n",
       "      <th>is_white_derived</th>\n",
       "      <th>is_othereth_derived</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>is_male_derived</th>\n",
       "      <th>AGE_AT_INCIDENT</th>\n",
       "      <th>age_derived</th>\n",
       "      <th>SENTENCE_DATE</th>\n",
       "      <th>sentenceymd_derived</th>\n",
       "      <th>sentenceym_derived</th>\n",
       "      <th>SENTENCE_JUDGE</th>\n",
       "      <th>judgeid_derived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109437</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12/20/2013 12:00:00 AM</td>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>William G Lacy</td>\n",
       "      <td>judge_331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61369</th>\n",
       "      <td>White [Hispanic or Latino]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7/20/2012 12:00:00 AM</td>\n",
       "      <td>2012-07-20</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>Michael J Howlett</td>\n",
       "      <td>judge_224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176916</th>\n",
       "      <td>White [Hispanic or Latino]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3/25/2016 12:00:00 AM</td>\n",
       "      <td>2016-03-25</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>Terence  MacCarthy</td>\n",
       "      <td>judge_298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67386</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11/27/2012 12:00:00 AM</td>\n",
       "      <td>2012-11-27</td>\n",
       "      <td>2012-11-01</td>\n",
       "      <td>James B Linn</td>\n",
       "      <td>judge_118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139910</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3/12/2015 12:00:00 AM</td>\n",
       "      <td>2015-03-12</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>Joan Margaret O'Brien</td>\n",
       "      <td>judge_135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55390</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6/27/2012 12:00:00 AM</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>Henry R Simmons</td>\n",
       "      <td>judge_104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164903</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8/17/2016 12:00:00 AM</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>Raymond  Myles</td>\n",
       "      <td>judge_259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242953</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1/22/2020 12:00:00 AM</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Thaddeus L Wilson</td>\n",
       "      <td>judge_300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1/11/2012 12:00:00 AM</td>\n",
       "      <td>2012-01-11</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>William T O'Brien</td>\n",
       "      <td>judge_333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171290</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>12/8/2016 12:00:00 AM</td>\n",
       "      <td>2016-12-08</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>Thomas J Hennelly</td>\n",
       "      <td>judge_308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              RACE  is_black_derived  is_hisp_derived  \\\n",
       "109437                       Black              True            False   \n",
       "61369   White [Hispanic or Latino]             False             True   \n",
       "176916  White [Hispanic or Latino]             False             True   \n",
       "67386                        Black              True            False   \n",
       "139910                       Black              True            False   \n",
       "55390                        Black              True            False   \n",
       "164903                       Black              True            False   \n",
       "242953                       Black              True            False   \n",
       "9953                      HISPANIC             False             True   \n",
       "171290                       Black              True            False   \n",
       "\n",
       "        is_white_derived  is_othereth_derived GENDER  is_male_derived  \\\n",
       "109437             False                False   Male             True   \n",
       "61369              False                False   Male             True   \n",
       "176916             False                False   Male             True   \n",
       "67386              False                False   Male             True   \n",
       "139910             False                False   Male             True   \n",
       "55390              False                False   Male             True   \n",
       "164903             False                False   Male             True   \n",
       "242953             False                False   Male             True   \n",
       "9953               False                False   Male             True   \n",
       "171290             False                False   Male             True   \n",
       "\n",
       "        AGE_AT_INCIDENT  age_derived           SENTENCE_DATE  \\\n",
       "109437             51.0         51.0  12/20/2013 12:00:00 AM   \n",
       "61369              46.0         46.0   7/20/2012 12:00:00 AM   \n",
       "176916             51.0         51.0   3/25/2016 12:00:00 AM   \n",
       "67386              20.0         20.0  11/27/2012 12:00:00 AM   \n",
       "139910             38.0         38.0   3/12/2015 12:00:00 AM   \n",
       "55390              23.0         23.0   6/27/2012 12:00:00 AM   \n",
       "164903             21.0         21.0   8/17/2016 12:00:00 AM   \n",
       "242953             20.0         20.0   1/22/2020 12:00:00 AM   \n",
       "9953               35.0         35.0   1/11/2012 12:00:00 AM   \n",
       "171290             53.0         53.0   12/8/2016 12:00:00 AM   \n",
       "\n",
       "       sentenceymd_derived sentenceym_derived         SENTENCE_JUDGE  \\\n",
       "109437          2013-12-20         2013-12-01         William G Lacy   \n",
       "61369           2012-07-20         2012-07-01      Michael J Howlett   \n",
       "176916          2016-03-25         2016-03-01     Terence  MacCarthy   \n",
       "67386           2012-11-27         2012-11-01           James B Linn   \n",
       "139910          2015-03-12         2015-03-01  Joan Margaret O'Brien   \n",
       "55390           2012-06-27         2012-06-01        Henry R Simmons   \n",
       "164903          2016-08-17         2016-08-01         Raymond  Myles   \n",
       "242953          2020-01-22         2020-01-01      Thaddeus L Wilson   \n",
       "9953            2012-01-11         2012-01-01      William T O'Brien   \n",
       "171290          2016-12-08         2016-12-01      Thomas J Hennelly   \n",
       "\n",
       "       judgeid_derived  \n",
       "109437       judge_331  \n",
       "61369        judge_224  \n",
       "176916       judge_298  \n",
       "67386        judge_118  \n",
       "139910       judge_135  \n",
       "55390        judge_104  \n",
       "164903       judge_259  \n",
       "242953       judge_300  \n",
       "9953         judge_333  \n",
       "171290       judge_308  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print a random sample of 10 rows \n",
    "df[[\"RACE\", \"is_black_derived\", \"is_hisp_derived\", \"is_white_derived\", \"is_othereth_derived\", \"GENDER\", \"is_male_derived\", \n",
    "    \"AGE_AT_INCIDENT\", \"age_derived\", \"SENTENCE_DATE\", \"sentenceymd_derived\", \"sentenceym_derived\", \"SENTENCE_JUDGE\", \"judgeid_derived\"]].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4: Subsetting rows to analytic dataset (5 points)\n",
    "\n",
    "You decide based on the above to simplify things in the following ways:\n",
    "    \n",
    "- Subset to cases where only one participant is charged, since cases with >1 participant might have complications like \n",
    "plea bargains/informing from other participants affecting the sentencing of the focal participant\n",
    "\n",
    "- To go from a participant-case level dataset, where each participant is repeated across charges tied to the case, to a participant-level dataset, where each participant has one charge, subset to a participant's primary charge and their current sentence (`PRIMARY_CHARGE_FLAG` is True and `CURRENT_SENTENCE_FLAG` is True). Double check that this worked by confirming there are no longer multiple charges for the same case-participant\n",
    "\n",
    "- Filter out observations where judge is nan or nonsensical (indicated by is.null or equal to FLOOD)\n",
    "\n",
    "- Subset to sentencing date between 01-01-2012 and 04-05-2021 (inclusive)\n",
    "\n",
    "After completing these steps, print the number of rows in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset to cases where only one participant is charged\n",
    "participants_per_case = df.groupby(\"CASE_ID\")[\"CASE_PARTICIPANT_ID\"].nunique()\n",
    "single_participant_cases = df[df[\"CASE_ID\"].isin(participants_per_case[participants_per_case == 1].index)]\n",
    "\n",
    "##Check:\n",
    "## participants_per_case_subset = single_participant_cases.groupby(\"CASE_ID\")[\"CASE_PARTICIPANT_ID\"].nunique()\n",
    "## print(participants_per_case_subset[participants_per_case_subset > 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## go from participant-case level data to a participant's primary charge and current sentence\n",
    "primary_current = single_participant_cases[\n",
    "    (single_participant_cases[\"PRIMARY_CHARGE_FLAG\"] == True) &\n",
    "    (single_participant_cases[\"CURRENT_SENTENCE_FLAG\"] == True)\n",
    "]\n",
    "\n",
    "## Check:\n",
    "## participant_charge_counts = primary_current.groupby(\"CASE_PARTICIPANT_ID\").size()\n",
    "## multiple_charges = participant_charge_counts[participant_charge_counts > 1]\n",
    "## print(f\"Number of participants with multiple charges: {len(multiple_charges)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter out observations where judge is nan or nonsensical:\n",
    "valid_judges = primary_current[\"SENTENCE_JUDGE\"].notna() & (primary_current[\"SENTENCE_JUDGE\"].str.strip().str.upper() != \"FLOOD\")\n",
    "\n",
    "primary_current = primary_current[valid_judges == True]\n",
    "\n",
    "## Check:\n",
    "## print(\"NaN judge count:\", primary_current[\"SENTENCE_JUDGE\"].isna().sum())\n",
    "## flood_judges = primary_current[\"SENTENCE_JUDGE\"].str.strip().str.upper() == \"FLOOD\"\n",
    "## print(\"FLOOD judge count:\", flood_judges.sum())\n",
    "\n",
    "## To see if any other null words appear for judges\n",
    "#null_strings = [\"null\", \"none\", \"nan\", \"na\", \"n/a\", \"\"]\n",
    "\n",
    "#judge_col = primary_current[\"SENTENCE_JUDGE\"].astype(str).str.strip().str.lower()\n",
    "#fake_null_judges = judge_col.isin(null_strings)\n",
    "\n",
    "#print(\"Fake 'null' judge count:\", fake_null_judges.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset to sentencing date between 01-01-2012 and 04-05-2021 (inclusive)\n",
    "\n",
    "start_date = pd.to_datetime(\"2012-01-01\")\n",
    "end_date = pd.to_datetime(\"2021-04-05\")\n",
    "\n",
    "filtered_data = primary_current[(primary_current[\"sentenceymd_derived\"] >= start_date) &\n",
    "(primary_current[\"sentenceymd_derived\"] <= end_date)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135165"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print number of rows in data\n",
    "len(filtered_data)\n",
    "\n",
    "## Check to see whether our cleaned data matched the version we read in for part 2:\n",
    "## filtered_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part two: investigating Black vs. White sentencing disparities\n",
    "\n",
    "Now that the data are cleaned, we're going to investigate different types of disparities in sentencing between Black defendants and White defendants. We're focusing on these groups for the purpose of the problem set, but the analysis could be extended to study Hispanic defendants or, in a different jurisdiction, Asian and other minoritized groups.\n",
    "\n",
    "**Details if interested in digging deeper**: If interested (optional), you can read more technical coverage of how we might (1) measure disparities, and (2) what factors you want to adjust for when deciding whether two defendants are 'similarly situated' but for their race in the following sources:\n",
    "\n",
    "- [Review of sentencing disparities research](https://www.journals.uchicago.edu/doi/full/10.1086/701505)\n",
    "- [Discussion of causal model/blinding race at charging stage of the prosecutorial process](https://5harad.com/papers/blind-charging.pdf)\n",
    "- [Discussion of measuring discrimination in policing that can generalize to the sentencing case](https://www.annualreviews.org/doi/abs/10.1146/annurev-criminol-011518-024731)\n",
    "- [General discussion of causal challenges in measuring between-group disparities](https://osf.io/preprints/socarxiv/gx4y3/)\n",
    "\n",
    "**One major caveat**: when investigating whether two similar defendants received different sentences, we're missing one important attribute that influences sentencing: the defendant's criminal history. This influences sentencing both through sentencing guidelines, which can prescribe longer sentences for those who have certain types of prior convictions, and through judicial discretion if judges are more lenient with first-time defendants. The above sources discuss how much we want to \"control away\" for this prior history, since if we think there are racial biases in which defendants, conditional on *committing* a crime, are arrested and charged, we may not want to adjust for that factor. More discussion [in this article](https://www.themarshallproject.org/2019/12/03/the-growing-racial-disparity-in-prison-time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0: (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read in the following dataset (regardless of progress on part one): `sentencing_cleaned.pkl` (if you can't read in the pkl you can read in the .csv format but may need to recast some of the datetime columns)\n",
    "\n",
    "*Note*: don't worry if there are slight differences in your output from Part One and this dataset/it's not a good use of time to try to reverse engineer Part One answers from this cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sentencing_cleaned.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentencing_cleaned.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m df_cleaned\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    186\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    188\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    189\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    190\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    191\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sentencing_cleaned.pkl'"
     ]
    }
   ],
   "source": [
    "df_cleaned = pd.read_pickle(\"sentencing_cleaned.pkl\")\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: Investigating one type of between-group difference: who reaches the sentencing stage? (5 points)\n",
    "\n",
    "Tabulate and visualize the proportion of defendants, out of all defendants sentenced in a given month/year, who are Black and who are White (separate proportions)\n",
    "\n",
    "- Denominator is number of unique cases that month\n",
    "- Numerator for black defendants is count of is_black_derived\n",
    "- Numerator for white defendants is count of is_white_derived\n",
    "- Fraction of each is numerator/denominator\n",
    "\n",
    "- Print the table\n",
    "- Create a graph with two lines--- one for Black defendants as fraction of total; another for White defendants. Make sure it includes a legend summarizing which color is for which group, and clean the legend so that it has informative names (e.g., Black or White rather than prop_black or prop_white)\n",
    "- Use mathematical notation to write out each of the proportions using summation notation in a 1-2 sentence writeup describing trends. What seems to be going on in April and May 2020? \n",
    "\n",
    "**Optional challenge**: improve the viz by shading the background of the visualization for months with fewer than 100 cases \n",
    "\n",
    "**Optional challenge**: improve the viz by adding a vertical line for 12-01-2016, the month that new State's Attorney Foxx took office "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## tabulate and visualize the proportion of defendants who are Black and White; print table\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m total_month_year \u001b[38;5;241m=\u001b[39m df_cleaned\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentenceym_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCASE_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## we use \"size\" because we want to count the number of rows where is_black_derived or is_white_derived\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m## is true for every year-month\u001b[39;00m\n\u001b[1;32m      6\u001b[0m black_month_year \u001b[38;5;241m=\u001b[39m df_cleaned[df_cleaned[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_black_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m]\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentenceym_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "## tabulate and visualize the proportion of defendants who are Black and White; print table\n",
    "total_month_year = df_cleaned.groupby(\"sentenceym_derived\")[\"CASE_ID\"].nunique()\n",
    "\n",
    "## we use \"size\" because we want to count the number of rows where is_black_derived or is_white_derived\n",
    "## is true for every year-month\n",
    "black_month_year = df_cleaned[df_cleaned[\"is_black_derived\"]==True].groupby(\"sentenceym_derived\").size()\n",
    "white_month_year = df_cleaned[df_cleaned[\"is_white_derived\"]==True].groupby(\"sentenceym_derived\").size()\n",
    "\n",
    "## printing the table by making a new data frame\n",
    "prop_table = pd.DataFrame()\n",
    "prop_table[\"black_proportion\"] = black_month_year / total_month_year\n",
    "prop_table[\"white_proportion\"] = white_month_year / total_month_year\n",
    "\n",
    "## reset index and rename column so it looks better:\n",
    "prop_table = prop_table.reset_index().rename(columns = {\"sentenceym_derived\": \"month_year\"})\n",
    "\n",
    "prop_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Create a graph with two lines--- one for Black defendants as fraction of total; another for White defendants. \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m## Make sure it includes a legend summarizing which color is for which group, and clean the legend so that it has informative names\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## (e.g., Black or White rather than prop_black or prop_white)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m## Black defendants line plot:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(prop_table\u001b[38;5;241m.\u001b[39mmonth_year, prop_table\u001b[38;5;241m.\u001b[39mblack_proportion,\n\u001b[1;32m      8\u001b[0m          label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlack\u001b[39m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcornflowerblue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "## Create a graph with two lines--- one for Black defendants as fraction of total; another for White defendants. \n",
    "## Make sure it includes a legend summarizing which color is for which group, and clean the legend so that it has informative names\n",
    "## (e.g., Black or White rather than prop_black or prop_white)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "## Black defendants line plot:\n",
    "plt.plot(prop_table.month_year, prop_table.black_proportion,\n",
    "         label=\"Black\", color=\"cornflowerblue\")\n",
    "plt.plot(prop_table.month_year, prop_table.white_proportion,\n",
    "         label=\"White\", color=\"firebrick\")\n",
    "\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Month/Year\", fontsize=15)\n",
    "plt.ylabel(\"Proportion of Total Defendants Sentenced\", fontsize=15)\n",
    "\n",
    "plt.title(\"Proportion of Black and White Defendants Sentenced Over Time\", fontsize=18)\n",
    "plt.legend(title=\"Defendant Race\", fontsize=15, title_fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (25575453.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[28], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    IDK WHAT THIS MEANS\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Use mathematical notation to write out each of the proportions using summation notation in a 1-2 sentence writeup describing trends. \n",
    "IDK WHAT THIS MEANS\n",
    "\n",
    "## What seems to be going on in April and May 2020?\n",
    "\n",
    "## In April and May 2020, there is a noticeable decrease in the proportion of Black defendants\n",
    "## and a noticeable increase in the proportion of White defendants sentenced compared to other months.\n",
    "## Perhaps this was in response to the Black Lives Matter movement, which drew attention to \n",
    "## discrimination on the basis of race in criminal justice proceedings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Investigating the first type of disparity: probation versus incaceration (10 points)\n",
    "\n",
    "One type of disparity beyond who arrives at the sentencing stage is whether the defendant receives probation or incaceration.\n",
    "\n",
    "According to the codebook, incarceration is indicated by `COMMITMENT_TYPE` == \"Illinois Department of Corrections\"\n",
    "\n",
    "Recreate the previous plot but where the y axis represents the difference between the following proportions (can be either Black - White or White - Black but make sure to label), adding a smoothed line:\n",
    "\n",
    "- Percent of black defendants who are incarcerated out of all black defendants that month/year \n",
    "- Percent of white defendants who are incarcerated out of all white defendants that month/year \n",
    "\n",
    "In a markdown cell after, write 1-2 sentences on your observations of trends over time. Do gaps seem to be widening or increasing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Making the table\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## First, make indicator of incarceration\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m incarc_month_year \u001b[38;5;241m=\u001b[39m df_cleaned[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOMMITMENT_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIllinois Department of Corrections\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m df_cleaned[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_incarc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m incarc_month_year\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m## Then look at total defendants per month/year vs those incarcerated for Black and White defendants\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "## Making the table\n",
    "\n",
    "## First, make indicator of incarceration\n",
    "incarc_month_year = df_cleaned[\"COMMITMENT_TYPE\"] == \"Illinois Department of Corrections\"\n",
    "df_cleaned[\"is_incarc\"] = incarc_month_year\n",
    "\n",
    "## Then look at total defendants per month/year vs those incarcerated for Black and White defendants\n",
    "black_month_year = df_cleaned[df_cleaned[\"is_black_derived\"]==True].groupby(\"sentenceym_derived\").size()\n",
    "black_incarc_month_year = df_cleaned[(df_cleaned[\"is_black_derived\"] == True) & (df_cleaned[\"is_incarc\"] == True)].groupby(\"sentenceym_derived\").size()\n",
    "\n",
    "white_month_year = df_cleaned[df_cleaned[\"is_white_derived\"]==True].groupby(\"sentenceym_derived\").size()\n",
    "white_incarc_month_year = df_cleaned[(df_cleaned[\"is_white_derived\"] == True) & (df_cleaned[\"is_incarc\"] == True)].groupby(\"sentenceym_derived\").size()\n",
    "\n",
    "\n",
    "## printing the table by making a new data frame\n",
    "incar_prop_table = pd.DataFrame()\n",
    "incar_prop_table[\"black_proportion_incarcerated\"] = black_incarc_month_year / black_month_year\n",
    "incar_prop_table[\"white_proportion_incarcerated\"] = white_incarc_month_year / white_month_year\n",
    "incar_prop_table[\"difference_black_white\"] = incar_prop_table[\"black_proportion_incarcerated\"] - incar_prop_table[\"white_proportion_incarcerated\"]\n",
    "\n",
    "## reset index and rename column so it looks better:\n",
    "incar_prop_table = incar_prop_table.reset_index().rename(columns = {\"sentenceym_derived\": \"month_year\"})\n",
    "incar_prop_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Recreate the previous plot but where the y axis represents the difference between the following proportions \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m## (can be either Black - White or White - Black but make sure to label), adding a smoothed line:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## to make the smooth line...\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m## Black and White plotted separately to show trend gap\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# plt.plot(incar_prop_table[\"month_year\"], incar_prop_table[\"black_proportion_incarceratated\"],\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#          label=\"Black Proportion Incarcerated\", color=\"cornflowerblue\", linestyle=\"--\", alpha = 0.5)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#          color=\"black\")\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate the moving average of the difference (Black - White)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m window_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Adjust this for smoother or more responsive lines\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "## Recreate the previous plot but where the y axis represents the difference between the following proportions \n",
    "## (can be either Black - White or White - Black but make sure to label), adding a smoothed line:\n",
    "\n",
    "## to make the smooth line...\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "## Black and White plotted separately to show trend gap\n",
    "# plt.plot(incar_prop_table[\"month_year\"], incar_prop_table[\"black_proportion_incarceratated\"],\n",
    "#          label=\"Black Proportion Incarcerated\", color=\"cornflowerblue\", linestyle=\"--\", alpha = 0.5)\n",
    "# plt.plot(incar_prop_table[\"month_year\"], incar_prop_table[\"white_proportion_incarcerated\"],\n",
    "#          label=\"White Proportion Incarcerated\", color=\"firebrick\", linestyle=\"--\", alpha = 0.5)\n",
    "\n",
    "## Black - White difference in proportion incarcerated overtime\n",
    "\n",
    "# plt.plot(incar_prop_table.month_year, incar_prop_table.difference_black_white,\n",
    "#          color=\"black\")\n",
    "# Calculate the moving average of the difference (Black - White)\n",
    "window_size = 3  # Adjust this for smoother or more responsive lines\n",
    "incar_prop_table[\"smoothed_difference\"] = incar_prop_table[\"difference_black_white\"].rolling(window=window_size, min_periods=1).mean()\n",
    "\n",
    "## used rolling instead of sns because month_year is not the write type\n",
    "plt.plot(incar_prop_table[\"month_year\"], incar_prop_table[\"smoothed_difference\"],\n",
    "         label=\"Smoothed Difference\", color=\"gray\", lw=2)\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Month/Year\", fontsize=15)\n",
    "plt.ylabel(\"Difference in Incarceration Proportion (Black - White)\", fontsize=15)\n",
    "plt.legend(title=\"Defendant Race\", fontsize=12, title_fontsize=12)\n",
    "plt.title(\"Difference in Proportion of Black and White Defendants Incarcerated\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###MARKDOWN CELL\n",
    "\n",
    "write 1-2 sentences on your observations of trends over time. Do gaps seem to be widening or increasing?\n",
    "\n",
    "While gaps skyrocketed up from a previous decline after 2020 (COVID), they steadily declined, but never reached the previous minimum. Most recently, the gap has been increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3: Investigating mechanisms: incaceration rates by charge\n",
    "\n",
    "Your colleague sees the previous graph and is worried that the gap could be different---either wider or smaller---if you adjust for the fact that prosecutors have discretion in what crimes to charge defendants with. If white defendants are charged with crimes that tend to receive probation rather than incarceration, that could explain some of the gaps.\n",
    "\n",
    "In the next questions, you'll begin to investigate this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1: Find the most common offenses (3 points)\n",
    "\n",
    "First, create a set of 'frequent offenses' that represent (over the entire period) the union of the 10 offenses Black defendant are most likely to be charged with and the 10 offenses white defendants are most likely to be charged with (might be far less than 20 total if there's a lot of overlap in common charges)\n",
    "\n",
    "Use the `simplified_offense_derived` for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m common_black \u001b[38;5;241m=\u001b[39m (df_cleaned[df_cleaned[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_black_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m]\n\u001b[1;32m      2\u001b[0m                [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimplified_offense_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m                 \u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      4\u001b[0m                 \u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m                 \u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m## Check:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m common_black\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "common_black = (df_cleaned[df_cleaned[\"is_black_derived\"]==True]\n",
    "               [\"simplified_offense_derived\"]\n",
    "                .value_counts()\n",
    "                .sort_values(ascending=False)\n",
    "                .head(10))\n",
    "## Check:\n",
    "common_black\n",
    "\n",
    "common_white = (df_cleaned[df_cleaned[\"is_white_derived\"]==True]\n",
    "               [\"simplified_offense_derived\"]\n",
    "                .value_counts()\n",
    "                .sort_values(ascending=False)\n",
    "                .head(10))\n",
    "\n",
    "## Check:\n",
    "common_white\n",
    "\n",
    "## set turns both data frames into sets so we can combine them into one union\n",
    "## we need .index in order to just grab the information for offense rather than the count\n",
    "frequent_offenses = set(common_black.index).union(set(common_white.index))\n",
    "print(frequent_offenses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2: Look at incarceration rates (again just whether incarcerated) by race and offense type for these top offenses (3 points)\n",
    "\n",
    "Print a wide-format version of the resulting table (so each row is an offense type, one col is black incarceration rate for that offense type; another is the white incarceration rate) and interpret. Which offenses show the largest disparities in judges being less likely to sentence White defendants to incarceration/more likely to offer those defendants probation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## First filter data for only top offenses and create an is_incarcerated column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df_cleaned[df_cleaned[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimplified_offense_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(frequent_offenses)]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      3\u001b[0m df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_incarcerated\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOMMITMENT_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIllinois Department of Corrections\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m## calculate Black incarceration rates by filtering for Black defendants and then\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m## calculating the mean of \"is_incarcerated\" for each offense in the the frequent offenses list:\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "## First filter data for only top offenses and create an is_incarcerated column\n",
    "df_filtered = df_cleaned[df_cleaned[\"simplified_offense_derived\"].isin(frequent_offenses)].copy()\n",
    "df_filtered[\"is_incarcerated\"] = df_filtered[\"COMMITMENT_TYPE\"] == \"Illinois Department of Corrections\"\n",
    "\n",
    "## calculate Black incarceration rates by filtering for Black defendants and then\n",
    "## calculating the mean of \"is_incarcerated\" for each offense in the the frequent offenses list:\n",
    "black_incarceration = (df_filtered[df_filtered[\"is_black_derived\"]==True]\n",
    "                      .groupby(\"simplified_offense_derived\")\n",
    "                       [\"is_incarcerated\"].mean()\n",
    "                      .rename(\"black incarceration rate\"))\n",
    "\n",
    "## calculate White incarceration rates by filtering for White defendants and then\n",
    "## calculating the mean of \"is_incarcerated\" for each offense in the the frequent offenses list:\n",
    "white_incarceration = (df_filtered[df_filtered[\"is_white_derived\"]==True]\n",
    "                      .groupby(\"simplified_offense_derived\")\n",
    "                       [\"is_incarcerated\"].mean()\n",
    "                      .rename(\"white incarceration rate\"))\n",
    "\n",
    "## is there another way to do this without concat?\n",
    "table = pd.concat([black_incarceration, white_incarceration], axis=1)\n",
    "\n",
    "table[\"Black - White\"] = (table[\"black incarceration rate\"] - table[\"white incarceration rate\"])\n",
    "\n",
    "table\n",
    "\n",
    "## Looking at the Black-White column, we see that Narcotics, Battery, and Unlawful Use of Weapon show the largest disparities\n",
    "## in judges being less likely to sentence White defendants to incarceration than Black defendants. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## instead of concat, use pivot_table\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## First filter data for only top offenses and create an is_incarcerated column\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df_cleaned[df_cleaned[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimplified_offense_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(frequent_offenses)]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      5\u001b[0m df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_incarcerated\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOMMITMENT_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIllinois Department of Corrections\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m## create a race column that only includes Black or White\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "## instead of concat, use pivot_table\n",
    "\n",
    "## First filter data for only top offenses and create an is_incarcerated column\n",
    "df_filtered = df_cleaned[df_cleaned[\"simplified_offense_derived\"].isin(frequent_offenses)].copy()\n",
    "df_filtered[\"is_incarcerated\"] = df_filtered[\"COMMITMENT_TYPE\"] == \"Illinois Department of Corrections\"\n",
    "\n",
    "## create a race column that only includes Black or White\n",
    "df_filtered = df_filtered[df_filtered[\"is_black_derived\"] | df_filtered[\"is_white_derived\"]].copy()\n",
    "df_filtered[\"race\"] = df_filtered[\"is_black_derived\"].map({True: \"Black\"}).fillna(\"White\")\n",
    "\n",
    "## create pivot table\n",
    "table = df_filtered.pivot_table(\n",
    "    index=\"simplified_offense_derived\",\n",
    "    columns=\"race\",\n",
    "    values=\"is_incarcerated\",\n",
    "    aggfunc=\"mean\"\n",
    ").rename(columns={\"Black\": \"black incarceration rate\", \"White\": \"white incarceration rate\"})\n",
    "\n",
    "## compute the disparity\n",
    "table[\"Black - White\"] = table[\"black incarceration rate\"] - table[\"white incarceration rate\"]\n",
    "\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3: Examine whether this changes pre and post change to charging threshold for retail theft (13 points)\n",
    "\n",
    "One important question is not only whether there are disparities by offense type but also whether these disparities are changing over time.\n",
    "\n",
    "The SAO, for instance, announced in December of 2016 that they would no longer default to charging retail thefts of under \\$1,000 as felonies. This change might have (1) decreased disparities or (2) increased disparities, depending on the correlation between race/ethnicity and magnitude of goods stolen: [news coverage](https://www.dnainfo.com/chicago/20161215/little-village/kim-foxx-raises-bar-for-retail-theft-felonies/). \n",
    "\n",
    "Focusing on `simplified_offense_derived` == \"Retail theft.\" Using a function and/or loop (Dec. 2016 is always excluded as a transition month):\n",
    "\n",
    "- Compare Black-White disparities before and after the change using a two-month bandwidth (so pre is October and November 2016; post is January and February 2017)\n",
    "\n",
    "- Compare Black-White disparities before and after the change using a four-month bandwidth (so pre is August- November 2016; post is January - April 2017)\n",
    "\n",
    "- Compare Black-White disparities using an eight-month bandwidth\n",
    "\n",
    "- Compare Black-White disparities using a twelve-month bandwidth\n",
    "\n",
    "\n",
    "------------------ \n",
    "\n",
    "- Print a table with the results (any organization is fine as long as it's clear)  \n",
    "\n",
    "- Create a bar chart where the x axis represents different bandwidths (2, 4, etc); the y axis the size of the Black-White gap in whether the defendant receives incarceration, and for each of the x axis points, you have one shaded bar representing \"before\" the change, another representing \"after\" the change (make sure that before is ordered before after and the bandwidths are from smallest to largest)\n",
    "\n",
    "*Note*: for each of the bandwidths include dates the entire month (e.g., for the first, include not only 02-01-2017 but everything up through 02-28-2017; easiest way is for the subsetting to use the rounded `sentenceym_derived`). Also make sure to only include white or black defendants.\n",
    "\n",
    "\n",
    "**Extra credit**: because the bandwidths have different sample sizes, a better viz incorporates measures of uncertainty. Add standard errors to the estimates using the formula: $(\\dfrac{p(1-p)}{n})^{0.5}$ where $p$ is the gap and $N$ is the number of cases in each bandwidth period \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## checking that setneceym_derived is of the datetime type \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentenceym_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## filtering to the data frame we are looking at in this problem\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m## retail, black and white, excluding december because its the transition month\u001b[39;00m\n\u001b[1;32m      7\u001b[0m df_retail \u001b[38;5;241m=\u001b[39m df_filtered[\n\u001b[1;32m      8\u001b[0m (df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimplified_offense_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetail Theft\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m      9\u001b[0m (df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentenceym_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m12\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     10\u001b[0m (df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_black_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_white_derived\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "## checking that setneceym_derived is of the datetime type \n",
    "print(df_filtered[\"sentenceym_derived\"].dtype)\n",
    "\n",
    "## filtering to the data frame we are looking at in this problem\n",
    "## retail, black and white, excluding december because its the transition month\n",
    "\n",
    "df_retail = df_filtered[\n",
    "(df_filtered[\"simplified_offense_derived\"] == \"Retail Theft\") &\n",
    "(df_filtered[\"sentenceym_derived\"].dt.month != 12) &\n",
    "(df_filtered[\"is_black_derived\"] | df_filtered[\"is_white_derived\"])]\n",
    "\n",
    "## check\n",
    "# df_retail\n",
    "\n",
    "## this data frame will go into the function as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_retail' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 34\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Compare Black-White disparities before and after the change using a two-month bandwidth \u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# (so pre is October and November 2016; post is January and February 2017)\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m bw_disparities(df_retail, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Compare Black-White disparities before and after the change using a four-month bandwidth\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# (so pre is August- November 2016; post is January - April 2017)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m bw_disparities(df_retail, \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_retail' is not defined"
     ]
    }
   ],
   "source": [
    "## Focusing on simplified_offense_derived == \"Retail theft.\" \n",
    "## Using a function and/or loop (Dec. 2016 is always excluded as a transition month):\n",
    "\n",
    "## function for comparing black-white disparities: (parameters are the data frame and then the bandwidth of months)\n",
    "def bw_disparities (df, bandwidth):\n",
    "\n",
    "    df = df.copy() #local copy so as not to modify the original\n",
    "    \n",
    "    #using pandas period range function co create the periods based on the december 2016 date\n",
    "    pre_months = pd.period_range(end = \"2016-11\", periods = bandwidth, freq = \"M\")\n",
    "    post_months = pd.period_range(start = \"2017-01\", periods = bandwidth, freq = \"M\")\n",
    "\n",
    "\n",
    "    df[\"period\"] = df[\"sentenceym_derived\"].apply(lambda x: \"pre\" if x in pre_months else \"post\")\n",
    "\n",
    "    # Using the pivot table logic from before within this function so that you can have a table be created for any month bandwidth \n",
    "    table = df.pivot_table(\n",
    "        index=\"period\",\n",
    "        columns=\"race\",\n",
    "        values=\"is_incarcerated\",\n",
    "        aggfunc=\"mean\"\n",
    "    ).rename(columns={\"Black\": \"black incarceration rate\", \"White\": \"white incarceration rate\"})\n",
    "\n",
    "    table.columns.name = None\n",
    "\n",
    "    table[\"Black - White\"] = table[\"black incarceration rate\"] - table[\"white incarceration rate\"]\n",
    "    table[\"Bandwidth\"] = bandwidth\n",
    "    \n",
    "    return table\n",
    "\n",
    "# Compare Black-White disparities before and after the change using a two-month bandwidth \n",
    "# (so pre is October and November 2016; post is January and February 2017)\n",
    "\n",
    "bw_disparities(df_retail, 2)\n",
    "\n",
    "# Compare Black-White disparities before and after the change using a four-month bandwidth\n",
    "# (so pre is August- November 2016; post is January - April 2017)\n",
    "\n",
    "bw_disparities(df_retail, 4)\n",
    "\n",
    "\n",
    "# Compare Black-White disparities using an eight-month bandwidth\n",
    "\n",
    "bw_disparities(df_retail, 8)\n",
    "\n",
    "# Compare Black-White disparities using a twelve-month bandwidth\n",
    "\n",
    "bw_disparities(df_retail, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_retail' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bw \u001b[38;5;129;01min\u001b[39;00m bandwidths:\n\u001b[0;32m---> 13\u001b[0m     result \u001b[38;5;241m=\u001b[39m bw_disparities(df_retail, bw)\n\u001b[1;32m     14\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreset_index()  \n\u001b[1;32m     15\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_retail' is not defined"
     ]
    }
   ],
   "source": [
    "##Create a bar chart where the x axis represents different bandwidths (2, 4, etc); \n",
    "##the y axis the size of the Black-White gap in whether the defendant receives incarceration, \n",
    "##and for each of the x axis points, you have one shaded bar representing \"before\" the change, \n",
    "##another representing \"after\" the change (make sure that before is ordered before after and the bandwidths are\n",
    "##from smallest to largest)\n",
    "\n",
    "## CREATING DF TO PLOT WITH\n",
    "\n",
    "bandwidths = [2, 4, 8, 12]\n",
    "results = []\n",
    "\n",
    "for bw in bandwidths:\n",
    "    result = bw_disparities(df_retail, bw)\n",
    "    result = result.reset_index()  \n",
    "    results.append(result)\n",
    "    \n",
    "results_df = pd.concat(results, ignore_index=True)\n",
    "results_df[\"period\"] = pd.Categorical(results_df[\"period\"], categories=[\"pre\", \"post\"], ordered=True)\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "## PLOTTING\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "sns.barplot(\n",
    "    data=results_df,\n",
    "    x=\"Bandwidth\",\n",
    "    y=\"Black - White\",\n",
    "    hue=\"period\",\n",
    "    palette=[\"pink\", \"cornflowerblue\"] \n",
    ")\n",
    "\n",
    "plt.title(\"Black-White Incarceration Gap by Bandwidth Before and After SAO's Change\")\n",
    "plt.xlabel(\"Bandwidth (months)\")\n",
    "plt.ylabel(\"Incarceration Gap (Black - White)\")\n",
    "plt.legend(title=\"Period\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## EXTRA CREDIT\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## getting the variables for the given formular\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m se_df \u001b[38;5;241m=\u001b[39m results_df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBandwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlack - White\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m      5\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# calculate the mean gap for each group\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m        \u001b[38;5;66;03m# count the number of observations in each group\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m## calculating standard error and putting it in data frame\u001b[39;00m\n\u001b[1;32m     10\u001b[0m se_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt((se_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m se_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m])) \u001b[38;5;241m/\u001b[39m se_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "## EXTRA CREDIT\n",
    "\n",
    "## getting the variables for the given formular\n",
    "se_df = results_df.groupby([\"Bandwidth\", \"period\"])[\"Black - White\"].agg(\n",
    "    p = \"mean\",  # calculate the mean gap for each group\n",
    "    n = \"count\"        # count the number of observations in each group\n",
    ")\n",
    "\n",
    "## calculating standard error and putting it in data frame\n",
    "se_df['SE'] = np.sqrt((se_df[\"p\"] * (1 - se_df[\"p\"])) / se_df[\"n\"])\n",
    "\n",
    "se_df_plot = pd.merge(results_df, se_df[['SE']], on=[\"Bandwidth\", \"period\"], how=\"left\")\n",
    "\n",
    "se_df_plot\n",
    "\n",
    "\n",
    "\n",
    "## PLOTTING\n",
    "# Plotting the results with error bars\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "## I wasn't sure if you wanted us to plot this, so I researched error bars to find the syntax. I hope thats okay!\n",
    "\n",
    "## First, I subset to pre and post than I plot error bars for each\n",
    "subset_pre = se_df_plot[se_df_plot['period'] == 'pre']\n",
    "plt.errorbar(subset_pre['Bandwidth'], subset_pre['Black - White'], yerr=subset_pre['SE'], fmt='o', capsize=5, label='Pre', color = \"cornflowerblue\")\n",
    "\n",
    "subset_post = se_df_plot[se_df_plot['period'] == 'post']\n",
    "plt.errorbar(subset_post['Bandwidth'], subset_post['Black - White'], yerr=subset_post['SE'], fmt='o', capsize=5, label='Post', color = \"red\", alpha = 0.5)\n",
    "\n",
    "plt.xlabel('Bandwidth')\n",
    "plt.ylabel('Black - White Incarceration Rate Gap')\n",
    "plt.title('Incarceration Rate Gaps by Bandwidth and Period with Error Bars')\n",
    "plt.legend(title=\"Period\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3.1: Interpret the results (2 points)\n",
    "\n",
    "Write a two-sentence interpretation of the results. What might this show about how people on both sides of the issue---those who argued that the retail theft policy change would narrow disparities; those who argued that the change may widen disparities--could support their claims? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears as if this policy change fits into a broader trend that was happening at the time anyway. You can see that from 12 months before the change to 4 months before the change, the gap had been steadily closing. If you were to just look at the 12 month bandwidth, you would assume the change is related to closing the gap, however, looking from 2 months post to 12 motnhs post the change, you can see that the gap did not decrease much, but rather this large picture decrease is part of a a pre-existing contextual trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
